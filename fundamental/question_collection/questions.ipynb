{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview Question: **In a deep neural network, is dividing the loss by 10 equivalent to dividing the learning rate by 10?**\n",
    "\n",
    "\n",
    "### Standard Answer\n",
    "\n",
    "The equivalence between scaling the **loss** and scaling the **learning rate** depends on the type of optimizer being used. Here's an analysis of common optimizers:\n",
    "\n",
    "\n",
    "#### **1. Traditional Optimizers (e.g., SGD and Momentum SGD)**\n",
    "\n",
    "**Stochastic Gradient Descent (SGD):**\n",
    "- SGD updates network parameters for each training sample, resulting in fast updates.\n",
    "- However, due to diverse training data, SGD often causes unstable training as it can deviate from the optimal direction.\n",
    "\n",
    "**Momentum SGD:**\n",
    "- Momentum helps SGD navigate challenging regions (e.g., steep valleys where gradients vary significantly along different axes).\n",
    "- By introducing a momentum term \\( m \\), the updates smoothen oscillations and accelerate convergence in the less-steep dimension.\n",
    "\n",
    "**Key Insight:**\n",
    "For traditional optimizers, scaling the **loss** by a constant directly affects the computed gradients and thus the parameter update magnitude.  \n",
    "- **Scaling the loss** (e.g., multiplying by 10) is equivalent to **scaling the learning rate** (e.g., multiplying by 10).  \n",
    "- Hence, **dividing the loss by 10 is equivalent to dividing the learning rate by 10**.\n",
    "\n",
    "\n",
    "\n",
    "#### **2. Optimizers with Second-Order Momentum (e.g., Adagrad, RMSprop)**\n",
    "\n",
    "**Adagrad:**\n",
    "- Adagrad adjusts the learning rate based on the frequency of feature updates. Rarely updated features get larger learning rates, while frequently updated features have smaller ones.\n",
    "- Its update rule incorporates an accumulated sum of squared gradients, resulting in diminishing learning rates over time.\n",
    "\n",
    "**RMSprop:**\n",
    "- RMSprop addresses Adagrad's diminishing learning rate issue by introducing a moving average of squared gradients.\n",
    "- It maintains stable learning rates throughout training, improving convergence.\n",
    "\n",
    "**Key Insight:**\n",
    "For optimizers with adaptive learning rates, scaling the **loss** affects gradient computation but not directly the parameter updates due to the adaptive mechanism.\n",
    "- **Scaling the loss is not equivalent to scaling the learning rate**.\n",
    "\n",
    "\n",
    "\n",
    "#### **3. Optimizers with Adaptive Learning Rates (e.g., Adam)**\n",
    "\n",
    "**Adam:**\n",
    "- Combines the advantages of momentum and adaptive learning rates by estimating both the first-order and second-order moments of the gradients.\n",
    "- Adam includes bias correction to address small initial moment values.\n",
    "\n",
    "**Key Insight:**\n",
    "In Adam:\n",
    "- Scaling the **loss** affects the gradient and its moments but has minimal impact on the overall parameter updates due to the adaptive mechanisms.\n",
    "- **Scaling the loss is not equivalent to scaling the learning rate**, as the latter directly impacts the magnitude of parameter updates.\n",
    "\n",
    "\n",
    "\n",
    "### **Summary Table**\n",
    "\n",
    "| **Optimizer**           | **Loss Scaling = Learning Rate Scaling?** | **Reason**                                                                 |\n",
    "|--------------------------|-------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| SGD / Momentum SGD       | Yes                                       | Directly affects gradient magnitudes, thus equivalent.                     |\n",
    "| Adagrad / RMSprop        | No                                        | Adaptive learning rate mechanisms mitigate loss scaling effects.           |\n",
    "| Adam                     | No                                        | Adaptive moment estimations decouple loss scaling from parameter updates. |\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Whether scaling the loss is equivalent to scaling the learning rate depends on the optimizer:\n",
    "\n",
    "- For **traditional optimizers** (e.g., SGD), **yes**, they are equivalent.  \n",
    "- For **adaptive optimizers** (e.g., Adagrad, RMSprop, Adam), **no**, they are not equivalent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为什么 Bert 的三个 Embedding 可以进行相加？\n",
    "\n",
    "频率分析（幅度分析）：\n",
    "\n",
    "在实际应用中，“叠加”是一种很常见的操作，例如对图像或者时间序列信号进行叠加。这意味着一个时序的波可以由多个不同频率的波形来表示。因此，通过改变不同波形的频率和幅度，可以将不同的输入信号映射到特定的表示上。这种方式也能够实现对时序信号的转化和理解。\n",
    "位置编码的应用：\n",
    "\n",
    "在自然语言处理中（NLP），一串文本不仅可以看作一些离散的标记（token），还可以理解为包含时序关系的信号。这些信号的频率和幅度是重要的特征，通过复杂的神经网络结构进行处理和理解。\n",
    "BERT模型中，token（标记）、position（位置）和segment（片段）三种信息被映射到不同的频率中，之后通过相加的方式将它们合并在一起，形成最终的表示。这种方法能够有效地让模型理解输入文本的顺序和结构信息。\n",
    "深层次理解：\n",
    "\n",
    "对于一串文本数据而言，如果将每个词的特征都进行叠加，就像是一步一步把每个成分逐步整合起来。这种方式有助于模型捕捉上下文之间的关联，也能体现出某些高频信号或低频信号的特性。\n",
    "\n",
    "\n",
    "\n",
    "Embedding的数学本质：\n",
    "\n",
    "Embedding的本质其实是对one hot向量进行降维的全连接操作。简单来说，one hot向量是一种稀疏的表示法，其中只有一个位置的值为1，其余位置的值都是0，而embedding通过某种方式将这个高维的稀疏表示降维为低维的稠密向量。\n",
    "从这个角度看，“embedding”其实并不是什么特别神秘的东西，而是one hot向量的一种延伸和变换。\n",
    "如何组合Token、Position、Segment三者的Embedding：\n",
    "\n",
    "在实际实现中，token、position、segment三者都会通过one hot向量进行表示，然后经过连接操作（concat）形成一个整体，最后再通过一个单层的全连接（dense layer）将它们的表示降维并得到最终的embedding。这意味着生成的embedding是三个不同信息的相加结果，从而能够将这些信息都编码到输入中。\n",
    "\n",
    "\n",
    "举例说明 Embedding 的计算过程\n",
    "假设矩阵维度：\n",
    "\n",
    "token embedding 的矩阵维度为 [4, 768]，position embedding 的矩阵维度为 [3, 768]，segment embedding 的矩阵维度为 [2, 768]。\n",
    "对于某一个字符，假设它的 token one-hot 表示为 [1, 0, 0, 0]，它的 position one-hot 表示为 [1, 0, 0]，segment one-hot 表示为 [1, 0]。\n",
    "计算 word embedding：\n",
    "\n",
    "将 token、position 和 segment 的 embedding 相加，得到最终的 word embedding。\n",
    "可以看到，这个 word embedding 是三个 embedding 的简单相加得到的。\n",
    "向量连接：\n",
    "\n",
    "将 one-hot 特征进行连接，即 [1, 0, 0, 0, 1, 0, 0, 1, 0]，然后经过全连接层（维度为 [4 + 3 + 2, 768] = [9, 768]）进行降维，得到的向量维度与原来的 embedding 相同，即 768。\n",
    "换个角度理解\n",
    "如果直接将 one-hot 特征 concat 起来，得到的 [1, 0, 0, 0, 1, 0, 0, 1, 0] 不再是一个标准的 one-hot 向量，而是具有多重特征的稀疏表示。其维度是 3 * 3 * 2 = 24，即包含更多的特征空间，能够表达更加丰富的信息。\n",
    "\n",
    "矩阵维度：\n",
    "\n",
    "通过上述连接和计算，最终得到的 embedding 维度是 [24, 768]，与直接计算出来的结果是一致的，但三者的连接方式会使得矩阵的维度增加，这反映出 embedding 空间维度的增长。\n",
    "总结\n",
    "特征融合：\n",
    "\n",
    "在 BERT 中，token embedding、position embedding 和 segment embedding 的相加，本质上是一种特征融合的过程。\n",
    "这种特征融合的方式使得每个 token 不仅包含自身的词汇信息，还结合了位置和句子的上下文信息，从而能够增强模型对序列的理解。\n",
    "最终得到的 embedding 特点：\n",
    "\n",
    "即使起始计算方式有所不同（如是否使用 concat），经过网络的进一步计算和 Layer Norm 等操作，最终得到的 embedding 分布是趋于一致的。\n",
    "BERT 使用了三个 embedding 的相加，目的是融合多方面的特征，以使模型能够学习到更多的关于序列的上下文、位置信息，以及 segment（句子对）等信息。\n",
    "总体而言，这张图片的解释使得 embedding 和位置编码的概念更加直观，通过举例展示了不同 embedding 如何结合在一起，以及如何通过降维和特征融合得到最终的词嵌入，帮助深度学习模型理解自然语言中的时序和语义信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Consequences of Initializing Weights with the Same Number\n",
    "\n",
    "\n",
    "Initializing all weights in a neural network with the same number can lead to significant issues during the training process. The primary consequence is the **symmetry problem**, which hinders the network's ability to learn effectively.\n",
    "\n",
    "$$\n",
    "\\text{Symmetry Problem}\n",
    "$$\n",
    "\n",
    "When all weights are initialized to the same value, such as zero, each neuron in a layer produces identical outputs and receives identical gradients during backpropagation. This means that all neurons update their weights in the same manner, leading to redundant features and preventing the network from learning diverse and useful representations.\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\sigma(\\mathbf{W} \\mathbf{x}) = \\sigma(\\mathbf{0} \\cdot \\mathbf{x}) = \\sigma(\\mathbf{0}) = \\text{constant}\n",
    "$$\n",
    "\n",
    "During backpropagation, the gradient for each weight becomes the same:\n",
    "\n",
    "$$\n",
    "\\Delta \\mathbf{w} = -\\eta \\frac{\\partial L}{\\partial \\mathbf{w}} = -\\eta \\cdot \\text{constant}\n",
    "$$\n",
    "\n",
    "This uniform update prevents the network from breaking the symmetry, causing all neurons to learn the same features and negating the benefits of having multiple neurons.\n",
    "\n",
    "$$\n",
    "\\text{Breaking Symmetry}\n",
    "$$\n",
    "\n",
    "To avoid the symmetry problem, weights are typically initialized with small random values. This ensures that each neuron starts with a unique set of weights, allowing them to learn different features and contribute uniquely to the network's performance.\n",
    "\n",
    "$$\n",
    "\\mathbf{w} \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is a small standard deviation. Alternatively, other initialization strategies like Xavier or He initialization are employed to maintain the variance of activations throughout the network, further promoting effective learning.\n",
    "\n",
    "$$\n",
    "\\text{Xavier Initialization: } \\mathbf{w} \\sim \\mathcal{N}\\left(0, \\frac{2}{n_{\\text{in}} + n_{\\text{out}}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{He Initialization: } \\mathbf{w} \\sim \\mathcal{N}\\left(0, \\frac{2}{n_{\\text{in}}}\\right)\n",
    "$$\n",
    "\n",
    "By initializing weights with appropriate random values, the network can break symmetry, allowing each neuron to learn distinct and meaningful features, which enhances the overall learning capability of the neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfoCSE Loss: temperature parameter effect\n",
    "\n",
    "- effect on vector space\n",
    "- number of batch size on negative and positive example;."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
